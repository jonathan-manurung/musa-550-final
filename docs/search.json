[
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Conclusive Overview",
    "section": "",
    "text": "In summary, the increase from 0.74 to 0.79 after adding 9 spatial features suggests an improvement and enhanced the predictive performance of house price prediction model.\nThe increase also suggest that the spatial features added, such as internal characteristic from property assessment, public amenity and disamenity features, and crimes, provide contribution in building a more accurate prediction model. Means that there are spatial patterns of neighborhood characteristic that affect the house prices.\nThe feature importance analysis plot presents which spatial features have the most significant impact on the model’s predictive performance. Total Livable Area, Distance to City Hall, Distance to Aggrevated Assault Crime are the top three significant features to the house price in Philadelphia"
  },
  {
    "objectID": "Data Wrangling.html",
    "href": "Data Wrangling.html",
    "title": "DATA WRANGLING",
    "section": "",
    "text": "Data form Philadelphia’s Open Data portal are used in building this model. The dataset that is expected to be significant features, in building a predictive model of house price"
  },
  {
    "objectID": "Data Wrangling.html#housing-sales-data",
    "href": "Data Wrangling.html#housing-sales-data",
    "title": "DATA WRANGLING",
    "section": "1. HOUSING SALES DATA",
    "text": "1. HOUSING SALES DATA\nInternal Characteristic of the House from data of Philadelphia Properties and Current Assessments\n\n\n\n\n\n\n\n\n\ngeometry\ncartodb_id\nassessment_date\nbasements\nbeginning_point\nbook_and_page\nbuilding_code\nbuilding_code_description\ncategory_code\ncategory_code_description\ncensus_tract\ncentral_air\ncross_reference\ndate_exterior_condition\ndepth\nexempt_building\nexempt_land\nexterior_condition\nfireplaces\nfrontage\nfuel\ngarage_spaces\ngarage_type\ngeneral_construction\ngeographic_ward\nhomestead_exemption\nhouse_extension\nhouse_number\ninterior_condition\nlocation\nmailing_address_1\nmailing_address_2\nmailing_care_of\nmailing_city_state\nmailing_street\nmailing_zip\nmarket_value\nmarket_value_date\nnumber_of_bathrooms\nnumber_of_bedrooms\nnumber_of_rooms\nnumber_stories\noff_street_open\nother_building\nowner_1\nowner_2\nparcel_number\nparcel_shape\nquality_grade\nrecording_date\nregistry_number\nsale_date\nsale_price\nseparate_utilities\nsewer\nsite_type\nstate_code\nstreet_code\nstreet_designation\nstreet_direction\nstreet_name\nsuffix\ntaxable_building\ntaxable_land\ntopography\ntotal_area\ntotal_livable_area\ntype_heater\nunfinished\nunit\nutility\nview_type\nyear_built\nyear_built_estimate\nzip_code\nzoning\npin\nbuilding_code_new\nbuilding_code_description_new\nobjectid\n\n\n\n\n1071\nPOINT (-75.14860 39.93145)\n18033\n2022-05-24T00:00:00Z\n0\n36'6\" E OF AMERICAN\n54131081\nR30\nROW B/GAR 2 STY MASONRY\n1\nSINGLE FAMILY\n27\nY\nNone\nNone\n90.0\n0.0\n0.0\n4\n0.0\n18.0\nNone\n1.0\nNone\nA\n1\n0\nNone\n224\n4\n224 WHARTON ST\nSIMPLIFILE LC E-RECORDING\nNone\nNone\nPHILADELPHIA PA\n224 WHARTON ST\n19147-5336\n327600\nNone\n2.0\n3.0\nNaN\n3.0\n711.0\nNone\nDEVER CATHERINE JOAN\nNone\n011001670\nE\nC\n2022-12-14T00:00:00Z\n9S17 307\n2022-12-05T00:00:00Z\n450000\nNone\nNone\nNone\nPA\n82740\nST\nNone\nWHARTON\nNone\n262080.0\n65520.0\nF\n1625.0\n1785.0\nA\nNone\nNone\nNone\nI\n1960\nY\n19147\nRSA5\n1001563093\n26\nROW RIVER ROW\n408100382\n\n\n13220\nPOINT (-75.14817 39.93101)\n33630\n2022-05-24T00:00:00Z\nA\n50' W SIDE OF 2ND ST\n54063610\nO50\nROW 3 STY MASONRY\n1\nSINGLE FAMILY\n27\nY\nNone\nNone\n36.0\n80000.0\n0.0\n3\n0.0\n34.0\nA\n0.0\nNone\nA\n1\n80000\nNone\n205\n3\n205 EARP ST\nSIMPLIFILE LC E-RECORDING\nNone\nNone\nPHILADELPHIA PA\n205 EARP ST\n19147-6035\n434400\nNone\n3.0\n4.0\nNaN\n3.0\n467.0\nNone\nMORAN KELLY\nTRENTALANGE SILVIO\n011004720\nE\nC+\n2022-06-30T00:00:00Z\n009S170369\n2022-06-24T00:00:00Z\n670000\nA\nNone\nNone\nPA\n30420\nST\nNone\nEARP\nNone\n267520.0\n86880.0\nF\n1224.0\n2244.0\nA\nNone\nNone\nNone\nI\n2009\nNone\n19147\nRSA5\n1001190209\n22\nROW TYPICAL\n408113583\n\n\n8348\nPOINT (-75.14781 39.93010)\n27578\n2022-05-24T00:00:00Z\nA\n33.333 S OF REED\n54085418\nP51\nROW W/GAR 3 STY MAS+OTHER\n1\nSINGLE FAMILY\n27\nY\nNone\nNone\n84.0\n574320.0\n0.0\n1\n0.0\n17.0\nA\n1.0\nNone\nC\n1\n0\nNone\n136\n1\n136 REED ST\nSIMPLIFILE LC E-RECORDING\nNone\nNone\nPHILADELPHIA PA\n136 REED ST\n19147-6117\n717900\nNone\n0.0\n3.0\nNaN\n2.0\n296.0\nNone\nDOLIN CARLY P\nDOLIN RYAN N\n011011410\nE\nC+\n2022-08-16T00:00:00Z\n010S110342\n2022-08-09T00:00:00Z\n790000\nNone\nY\nNone\nPA\n67780\nST\nNone\nREED\nNone\n0.0\n143580.0\nF\n1400.0\n2514.0\nA\nNone\nNone\nNone\nI\n2014\nNone\n19147\nICMX\n1001442221\n25\nROW MODERN\n408108984\n\n\n1179\nPOINT (-75.14887 39.93026)\n18296\n2022-05-24T00:00:00Z\nD\n68 FT W PHILIP ST\n54127951\nO50\nROW 3 STY MASONRY\n1\nSINGLE FAMILY\n27\nY\nNone\nNone\n60.0\n180200.0\n0.0\n4\n0.0\n14.0\nNone\n0.0\nNone\nA\n1\n0\nNone\n220\n4\n220 REED ST\nOLKOWSKI KEITH\nNone\nNone\nPHILADELPHIA PA\n243 GREENWICH STREET\n19147\n293000\nNone\n2.0\n3.0\nNaN\n3.0\n193.0\nNone\nOLKOWSKI KEITH\nRACHUBINSKI MICHAEL\n011012200\nE\nC\n2022-12-06T00:00:00Z\n010S110109\n2022-12-02T00:00:00Z\n195000\nNone\nNone\nNone\nPA\n67780\nST\nNone\nREED\nNone\n54200.0\n58600.0\nF\n840.0\n1358.0\nH\nNone\nNone\nNone\nI\n1920\nY\n19147\nRSA5\n1001442236\n22\nROW TYPICAL\n408100883\n\n\n13192\nPOINT (-75.14881 39.93012)\n33595\n2022-05-24T00:00:00Z\nC\n42 FT W PHILIP\n54063384\nO30\nROW 2 STY MASONRY\n1\nSINGLE FAMILY\n27\nY\nNone\nNone\n39.0\n0.0\n0.0\n4\n0.0\n14.0\nNone\n0.0\nNone\nA\n1\n0\nNone\n207\n3\n207 GERRITT ST\nSIMPLIFILE LC E-RECORDING\nNone\nNone\nPHILADELPHIA PA\n207 GERRITT ST\n19147-6012\n255500\nNone\n2.0\n2.0\nNaN\n2.0\n141.0\nNone\nNETTER DANIEL ANTHONY\nNETTER SARAH ANNE\n011014000\nE\nC\n2022-06-29T00:00:00Z\n010S110172\n2022-06-27T00:00:00Z\n331000\nNone\nNone\nNone\nPA\n36680\nST\nNone\nGERRITT\nNone\n204400.0\n51100.0\nF\n546.0\n868.0\nH\nNone\nNone\nNone\nI\n1920\nY\n19147\nRSA5\n1001238775\n22\nROW TYPICAL\n408113799"
  },
  {
    "objectID": "Data Wrangling.html#feature-from-sales-data-we-will-work-with",
    "href": "Data Wrangling.html#feature-from-sales-data-we-will-work-with",
    "title": "DATA WRANGLING",
    "section": "Feature from sales data we will work with:",
    "text": "Feature from sales data we will work with:\n\nSale Price\nTotal Livable Area\nTotal Area\nGarage Spaces\nFireplace\nFrontage\nNumber of Bathrooms\nNumber of Bedrooms\nNumber of Stories\nExterior Condition\nInterior Condition\nZip Code\nGarage Type\nZoning"
  },
  {
    "objectID": "Data Wrangling.html#feature-1-311-graffiti-calls",
    "href": "Data Wrangling.html#feature-1-311-graffiti-calls",
    "title": "DATA WRANGLING",
    "section": "2. FEATURE 1: 311 GRAFFITI CALLS",
    "text": "2. FEATURE 1: 311 GRAFFITI CALLS\nSource: https://www.opendataphilly.org/dataset/311-service-and-information-requests\nMetadata\n\n\n\n\n\n\n\n\n\ngeometry\ncartodb_id\nobjectid\nservice_request_id\nsubject\nstatus\nstatus_notes\nservice_name\nservice_code\nagency_responsible\nservice_notice\nrequested_datetime\nupdated_datetime\nexpected_datetime\nclosed_datetime\naddress\nzipcode\nmedia_url\nlat\nlon\n\n\n\n\n0\nPOINT (-75.08690 40.01072)\n124\n23123130\n14779871\nGraffiti Removal\nClosed\nIssue Resolved\nGraffiti Removal\nSR-CL01\nCommunity Life Improvement Program\n7 Business Days\n2022-03-07T13:46:57Z\n2023-02-15T22:01:20Z\n2022-03-16T20:00:00Z\n2022-03-11T10:48:00Z\n4301-29 PAUL ST\n19124\nNone\n40.010720\n-75.086897\n\n\n1\nPOINT (-75.16784 39.93091)\n125\n23205514\n14882961\nGraffiti Removal\nClosed\nOther\nGraffiti Removal\nSR-CL01\nCommunity Life Improvement Program\n7 Business Days\n2022-04-22T15:44:26Z\n2022-05-03T08:00:11Z\n2022-05-03T20:00:00Z\n2022-04-26T13:53:30Z\n1527 S BROAD ST\n19147\nhttps://d17aqltn7cihbm.cloudfront.net/uploads/...\n39.930912\n-75.167842\n\n\n2\nPOINT (-75.21926 39.95372)\n248\n23205508\n14883241\nGraffiti Removal\nClosed\nIssue Resolved\nGraffiti Removal\nSR-CL01\nCommunity Life Improvement Program\n7 Business Days\n2022-04-22T17:30:03Z\n2022-05-04T10:08:37Z\n2022-05-03T20:00:00Z\n2022-05-04T10:08:35Z\n4832 SPRUCE ST\n19139\nhttps://d17aqltn7cihbm.cloudfront.net/uploads/...\n39.953722\n-75.219259\n\n\n3\nPOINT (-75.14260 39.97323)\n668\n23205579\n14882570\nGraffiti Removal\nClosed\nIssue Resolved\nGraffiti Removal\nSR-CL01\nCommunity Life Improvement Program\n7 Business Days\n2022-04-22T14:14:02Z\n2022-04-29T11:18:39Z\n2022-05-03T20:00:00Z\n2022-04-29T11:18:38Z\n1432 N 4TH ST\n19122\nhttps://d17aqltn7cihbm.cloudfront.net/uploads/...\n39.973229\n-75.142603\n\n\n4\nPOINT (-75.16772 40.00350)\n843\n23123114\n14780160\nGraffiti Removal\nClosed\nIssue Resolved\nGraffiti Removal\nSR-CL01\nCommunity Life Improvement Program\n7 Business Days\n2022-03-07T14:43:46Z\n2023-02-15T22:00:12Z\n2022-03-16T20:00:00Z\n2022-03-10T09:46:48Z\n2306 W ALLEGHENY AVE\n19132\nhttps://d17aqltn7cihbm.cloudfront.net/uploads/...\n40.003501\n-75.167723\n\n\n\n\n\n\n\n\nHex map of the 311 Graffiti Calls"
  },
  {
    "objectID": "Data Wrangling.html#feature-2-subway-stops",
    "href": "Data Wrangling.html#feature-2-subway-stops",
    "title": "DATA WRANGLING",
    "section": "3. FEATURE 2: SUBWAY STOPS",
    "text": "3. FEATURE 2: SUBWAY STOPS\nSource: OSM Wikipedia\n\n\n\n\n\n\n\n\n\n\naddr:city\nname\nnetwork\noperator\nplatforms\npublic_transport\nrailway\nstation\nsubway\nwheelchair\nwikidata\nwikipedia\ngeometry\naddr:postcode\noperator_1\naddr:housenumber\naddr:street\nrailway:position\ninternet_access\nname:en\nold_name\naddr:state\nshort_name\nnetwork:wikidata\ntrain\noperator:wikidata\nelevator\ntram\n\n\nelement_type\nosmid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnode\n469917297\nPhiladelphia\n15th-16th & Locust\nPATCO\nPATCO\n1\nstation\nstation\nsubway\nyes\nyes\nQ4551078\nen:15–16th & Locust (PATCO station)\nPOINT (-8367552.610 4858465.747)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n469917298\nPhiladelphia\n9th-10th & Locust\nPATCO\nPATCO\n1\nstation\nstation\nsubway\nyes\nyes\nQ4646737\nen:9–10th & Locust (PATCO station)\nPOINT (-8366424.042 4858281.683)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n471026103\nPhiladelphia\n12th-13th & Locust\nPATCO\nPATCO\n1\nstation\nstation\nsubway\nyes\nno\nQ4548965\nen:12–13th & Locust (PATCO station)\nPOINT (-8366949.703 4858366.817)\n19107\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n650938316\nNaN\n63rd Street\nSEPTA\nSEPTA\nNaN\nstation\nstation\nsubway\nyes\nNaN\nNaN\nNaN\nPOINT (-8376424.717 4860524.238)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n650959043\nNaN\n56th Street\nSEPTA\nSEPTA\nNaN\nstation\nstation\nsubway\nyes\nNaN\nQ4640769\nNaN\nPOINT (-8374883.844 4860274.795)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nTwo Main SEPTA Line Stop\n\n\n\n\n\n\n\nHex map of the Subway Stop"
  },
  {
    "objectID": "Data Wrangling.html#feature-3-distance-to-universities",
    "href": "Data Wrangling.html#feature-3-distance-to-universities",
    "title": "DATA WRANGLING",
    "section": "4. FEATURE 3: DISTANCE TO UNIVERSITIES",
    "text": "4. FEATURE 3: DISTANCE TO UNIVERSITIES\n\nSource: OpenDataPhilly\nGeoJSON URL\n\n\nHex map of the distance to nearest University/College"
  },
  {
    "objectID": "Data Wrangling.html#feature-4-distance-to-park",
    "href": "Data Wrangling.html#feature-4-distance-to-park",
    "title": "DATA WRANGLING",
    "section": "5. FEATURE 4: DISTANCE TO PARK",
    "text": "5. FEATURE 4: DISTANCE TO PARK\n\nSource: OpenDataPhilly\nGeoJSON URL\n\n\nHex map of the distance to nearest Park"
  },
  {
    "objectID": "Data Wrangling.html#feature-5-distance-to-city-hall",
    "href": "Data Wrangling.html#feature-5-distance-to-city-hall",
    "title": "DATA WRANGLING",
    "section": "6. FEATURE 5: DISTANCE TO CITY HALL",
    "text": "6. FEATURE 5: DISTANCE TO CITY HALL\n\nSource: OpenDataPhilly\nGeoJSON URL\n\n\nHex map of the distance to City Hall"
  },
  {
    "objectID": "Data Wrangling.html#feature-6-distance-to-5-nearest-residential-construction-permits-from-2022",
    "href": "Data Wrangling.html#feature-6-distance-to-5-nearest-residential-construction-permits-from-2022",
    "title": "DATA WRANGLING",
    "section": "7. FEATURE 6: DISTANCE TO 5 NEAREST RESIDENTIAL CONSTRUCTION PERMITS FROM 2022",
    "text": "7. FEATURE 6: DISTANCE TO 5 NEAREST RESIDENTIAL CONSTRUCTION PERMITS FROM 2022\n\nSource: OpenDataPhilly\nCARTO table name: “permits”\n\n\nHex map of the distance to 5 closest building permits"
  },
  {
    "objectID": "Data Wrangling.html#feature-7-distance-to-the-5-nearest-aggravated-assault-in-2022",
    "href": "Data Wrangling.html#feature-7-distance-to-the-5-nearest-aggravated-assault-in-2022",
    "title": "DATA WRANGLING",
    "section": "8. FEATURE 7: DISTANCE TO THE 5 NEAREST AGGRAVATED ASSAULT IN 2022",
    "text": "8. FEATURE 7: DISTANCE TO THE 5 NEAREST AGGRAVATED ASSAULT IN 2022\n\nSource: OpenDataPhilly\n\n\nHex map of the distance to 5 closest aggravated assault"
  },
  {
    "objectID": "Data Wrangling.html#feature-8-distance-to-the-5-nearest-abandoned-vehicle-311-calls-in-2022",
    "href": "Data Wrangling.html#feature-8-distance-to-the-5-nearest-abandoned-vehicle-311-calls-in-2022",
    "title": "DATA WRANGLING",
    "section": "9. FEATURE 8: DISTANCE TO THE 5 NEAREST ABANDONED VEHICLE 311 CALLS IN 2022",
    "text": "9. FEATURE 8: DISTANCE TO THE 5 NEAREST ABANDONED VEHICLE 311 CALLS IN 2022\n\nSource: OpenDataPhilly\n\n\nHex map of the distance to 5 nearest abandoned vehicle 311 calls in 2022"
  },
  {
    "objectID": "Data Wrangling.html#feature-9-distance-to-the-5-nearest-homeless-encampment-request-in-2022",
    "href": "Data Wrangling.html#feature-9-distance-to-the-5-nearest-homeless-encampment-request-in-2022",
    "title": "DATA WRANGLING",
    "section": "10. FEATURE 9: DISTANCE TO THE 5 NEAREST HOMELESS ENCAMPMENT REQUEST IN 2022",
    "text": "10. FEATURE 9: DISTANCE TO THE 5 NEAREST HOMELESS ENCAMPMENT REQUEST IN 2022\n\nSource: OpenDataPhilly\n\n\nHex map of the distance to 5 nearest homeless encampment request in 2022"
  },
  {
    "objectID": "analysis/Analysis and Result.html#housing-sales-data",
    "href": "analysis/Analysis and Result.html#housing-sales-data",
    "title": "BUILDING THE PREDICTIVE MODEL",
    "section": "HOUSING SALES DATA",
    "text": "HOUSING SALES DATA\n\n\nCode\n# the CARTO API url\ncarto_url = \"https://phl.carto.com/api/v2/sql\"\n\n# Only pull 2022 sales for single family residential properties\nwhere = \"sale_date &gt;= '2022-01-01' and sale_date &lt;= '2022-12-31'\"\nwhere = where + \" and category_code_description IN ('SINGLE FAMILY', 'Single Family')\"\n\n# Create the query\nquery = f\"SELECT * FROM opa_properties_public WHERE {where}\"\n\n# Make the request\nparams = {\"q\": query, \"format\": \"geojson\"}\nresponse = requests.get(carto_url, params=params)\n\n# Make the GeoDataFrame\nsalesRaw = gpd.GeoDataFrame.from_features(response.json(), crs=\"EPSG:4326\")\n\n# Optional: put it a reproducible order for test/training splits later\nsalesRaw = salesRaw.sort_values(\"parcel_number\")\n\n\n\nSelecting Columns, Remove NaN Value, Remove Very High and Very Low Sales Prices\n\n\nCode\n# The feature columns we want to use\ncols = [\n    \"sale_price\",\n    \"total_livable_area\",\n    \"total_area\",\n    \"garage_spaces\",\n    \"fireplaces\",\n    \"frontage\",\n    \"number_of_bathrooms\",\n    \"number_of_bedrooms\",\n    \"number_stories\",\n    \"exterior_condition\",\n    \"interior_condition\",\n    \"zip_code\",\n    \"garage_type\",\n    \"zoning\"\n]\n\n# Trim to these columns and remove NaNs\nsales = salesRaw[cols + [\"geometry\"]].dropna()\n\n# Trim zip code to only the first five digits\nsales[\"zip_code\"] = sales[\"zip_code\"].astype(str).str.slice(0, 5)\n\n# Trim very low and very high sales\nvalid = (sales['sale_price'] &gt; 3000) & (sales['sale_price'] &lt; 1e6)\nsales = sales.loc[valid]\n\n\n\n\nSplit the data into training and test set (70/30)\n\n\nCode\n# Split the data 70/30\ntrain_set, test_set = train_test_split(sales, test_size=0.3, random_state=42)\n\n# the target labels: log of sale price\ny_train = np.log(train_set[\"sale_price\"])\ny_test = np.log(test_set[\"sale_price\"])\n\n\n\n\nSelecting Numerical Features:\n“total_livable_area”, “total_area”, “garage_spaces”, “fireplaces”, “frontage”, “number_of_bathrooms”, “number_of_bedrooms”, “number_stories”\n\n\nScore of a linear regression model as a baseline:\n\n\nCode\n# Make a linear model pipeline\nlinear_pipeline = make_pipeline(StandardScaler(), LinearRegression())\n\n# Fit on the training data\nlinear_pipeline.fit(X_train, y_train)\n\n# What's the test score?\nlinear_pipeline.score(X_test, y_test)\n\n\n0.48149900155901426\n\n\n\n\nResult of cross-validation on a random forest model:\n\n\nCode\n# Make a random forest pipeline\nforest_pipeline = make_pipeline(\n    StandardScaler(), RandomForestRegressor(n_estimators=100, random_state=42)\n)\n\n# Run the 10-fold cross validation\nscores = cross_val_score(\n    forest_pipeline,\n    X_train,\n    y_train,\n    cv=10,\n)\n\n# Report\nprint(\"R^2 scores = \", scores)\nprint(\"Scores mean = \", scores.mean())\nprint(\"Score std dev = \", scores.std())\n\n\nR^2 scores =  [0.527394   0.49451605 0.6344734  0.55960568 0.59060613 0.54684389\n 0.60374838 0.44244995 0.50146811 0.47442473]\nScores mean =  0.5375530322895475\nScore std dev =  0.05783592441257988\n\n\n\n\nScore of random forest model:\n\n\nCode\n# Fit on the training data\nforest_pipeline.fit(X_train, y_train)\n\n# What's the test score?\nforest_pipeline.score(X_test, y_test)\n\n\n0.6255116826480132\n\n\n\nSet Up Transformer for Numerical and categorical columns:\n\n\nCode\n# Set up the column transformer with two transformers\n# ----&gt; Scale the numerical columns\n# ----&gt; One-hot encode the categorical columns\n\ntransformer = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    ]\n)\n\n# Initialize the pipeline\n# NOTE: only use 10 estimators here so it will run in a reasonable time\npipe = make_pipeline(\n    transformer, RandomForestRegressor(n_estimators=10, \n                                       random_state=42)\n)\n\n# Fit the training set\npipe.fit(train_set, y_train);\n\n\n\n\n\nTest Score of pipe model:\n\n\n0.7430072213389314"
  },
  {
    "objectID": "analysis/Analysis and Result.html#adding-spatial-features-distance-based-to-the-housing-price-model",
    "href": "analysis/Analysis and Result.html#adding-spatial-features-distance-based-to-the-housing-price-model",
    "title": "BUILDING THE PREDICTIVE MODEL",
    "section": "Adding spatial features (distance-based) to the housing price model",
    "text": "Adding spatial features (distance-based) to the housing price model\n\nAdding spatial amenity/disamenity features (311 Request, Crime Incidents, Open Street Map)\n\n\nFEATURE 1: 311 GRAFFITI CALLS\n\n\nCode\ndef get_carto_data(table_name, where=None, limit=None):\n    \"\"\"\n    Download data from CARTO given a specific table name and\n    optionally a where statement or limit.\n    \"\"\"\n\n    # the CARTO API url\n    carto_url = \"https://phl.carto.com/api/v2/sql\"\n\n    # Create the query\n    query = f\"SELECT * FROM {table_name}\"\n\n    # Add a where\n    if where is not None:\n        query = query + f\" WHERE {where}\"\n\n    # Add a limit\n    if limit is not None:\n        query = query + f\" LIMIT {limit}\"\n\n    # Make the request\n    params = {\"q\": query, \"format\": \"geojson\"}\n    response = requests.get(carto_url, params=params)\n\n    # Make the GeoDataFrame\n    return gpd.GeoDataFrame.from_features(response.json(), crs=\"EPSG:4326\")\n\ntable_name = \"public_cases_fc\"\n\nget_carto_data(table_name, limit=5);\n\n# Select only those for grafitti and in 2022\nwhere = \"requested_datetime &gt;= '01-01-2022' and requested_datetime &lt; '01-01-2023'\"\nwhere = where + \" and service_name = 'Graffiti Removal'\"\n\n# Pull the subset we want\ngraffiti = get_carto_data(table_name, where=where)\n\n# Remove rows with empty or NaN geometries\nnot_missing = (~graffiti.geometry.is_empty) & (graffiti.geometry.notna())\ngraffiti = graffiti.loc[not_missing]\n\nlen(graffiti);\n\n# Do the CRS conversion\nsales_3857 = sales.to_crs(epsg=3857)\ngraffiti_3857 = graffiti.to_crs(epsg=3857)\n\ndef get_xy_from_geometry(df):\n    \"\"\"\n    Return a numpy array with two columns, where the \n    first holds the `x` geometry coordinate and the second \n    column holds the `y` geometry coordinate\n    \"\"\"\n    x = df.geometry.x\n    y = df.geometry.y\n    \n    return np.column_stack((x, y)) # stack as columns\n\n# Extract x/y for sales\nsalesXY = get_xy_from_geometry(sales_3857)\n\n# Extract x/y for grafitti calls\ngraffitiXY = get_xy_from_geometry(graffiti_3857)\n\nsalesXY.shape\n\ngraffitiXY.shape;\n\n# STEP 1: Initialize the algorithm\nk = 5\nnbrs = NearestNeighbors(n_neighbors=k)\n\n# STEP 2: Fit the algorithm on the \"neighbors\" dataset\nnbrs.fit(graffitiXY)\n\n# STEP 3: Get distances for sale to neighbors\ngrafDists, grafIndices = nbrs.kneighbors(salesXY) \n\n# The distances from the first sale to the 5 nearest neighbors\ngrafDists[0];\n\ngrafIndices[0];\n\nsalesXY[0];\n\n# The coordinates for the first sale\nx0, y0 = salesXY[0]\nx0, y0;\n\n# The indices for the 5 nearest graffiti calls\ngrafIndices[0];\n\n# the graffiti neighbors\nsale0_neighbors = graffitiXY[grafIndices[0]]\nsale0_neighbors;\n\n# Access the first and second column for x/y values\nneighbors_x = sale0_neighbors[:,0]\nneighbors_y = sale0_neighbors[:,1]\n\n# The x/y differences between neighbors and first sale coordinates\ndx = (neighbors_x - x0)\ndy = (neighbors_y - y0)\n\n# The Euclidean dist\nmanual_dists = (dx**2 + dy**2) ** 0.5\n\nmanual_dists;\n\ngrafDists[0];\n\ngrafDists.mean(axis=1);\n\n# Average distance to neighbors\navgGrafDist = grafDists.mean(axis=1)\n\n# Set zero distances to be small, but nonzero\n# IMPORTANT: THIS WILL AVOID INF DISTANCES WHEN DOING THE LOG\navgGrafDist[avgGrafDist==0] = 1e-5\n\n# Calculate log of distances\nsales['logDistGraffiti'] = np.log10(avgGrafDist)\n\n\n\n\nFEATURE 2: SUBWAY STOPS\n\n\nCode\n# Get the subway stops within the city limits\nsubway = ox.features_from_polygon(city_limits_outline, tags={\"station\": \"subway\"})\n\n# Convert to 3857 (meters)\nsubway = subway.to_crs(epsg=3857)\n\n# STEP 1: x/y coordinates of subway stops (in EPGS=3857)\nsubwayXY = get_xy_from_geometry(subway.to_crs(epsg=3857))\n\n# STEP 2: Initialize the algorithm\nnbrs = NearestNeighbors(n_neighbors=1)\n\n# STEP 3: Fit the algorithm on the \"neighbors\" dataset\nnbrs.fit(subwayXY)\n\n# STEP 4: Get distances for sale to neighbors\nsubwayDists, subwayIndices = nbrs.kneighbors(salesXY)\n\n# STEP 5: add back to the original dataset\nsales[\"logDistSubway\"] = np.log10(subwayDists.mean(axis=1))\n\n\n\n\nFEATURE 3: DISTANCE TO UNIVERSITIES\n\n\nCode\n# Get the data\nurl = \"https://opendata.arcgis.com/api/v3/datasets/8ad76bc179cf44bd9b1c23d6f66f57d1_0/downloads/data?format=geojson&spatialRefId=4326\"\nunivs = gpd.read_file(url)\n\n# Get the X/Y\nunivXY = get_xy_from_geometry(univs.to_crs(epsg=3857))\n\n# Run the k nearest algorithm\nnbrs = NearestNeighbors(n_neighbors=1)\nnbrs.fit(univXY)\nunivDists, _ = nbrs.kneighbors(salesXY)\n\n# Add the new feature\nsales['logDistUniv'] = np.log10(univDists.mean(axis=1))\n\n\n\n\nFEATURE 4: DISTANCE TO PARK\n\n\nCode\n# Get the data\nurl = \"https://opendata.arcgis.com/datasets/d52445160ab14380a673e5849203eb64_0.geojson\"\nparks = gpd.read_file(url)\n\n# Get the X/Y\nparksXY = get_xy_from_geometry(parks.to_crs(epsg=3857))\n\n# Run the k nearest algorithm\nnbrs = NearestNeighbors(n_neighbors=1)\nnbrs.fit(parksXY)\nparksDists, _ = nbrs.kneighbors(salesXY)\n\n# Add the new feature\nsales[\"logDistParks\"] = np.log10(parksDists.mean(axis=1))\n\n\n\n\nFEATURE 5: DISTANCE TO CITY HALL\n\n\nCode\n# Get the data\nurl = \"http://data-phl.opendata.arcgis.com/datasets/5146960d4d014f2396cb82f31cd82dfe_0.geojson\"\nlandmarks = gpd.read_file(url)\n\n# Trim to City Hall\ncityHall = landmarks.query(\"NAME == 'City Hall' and FEAT_TYPE == 'Municipal Building'\")\n\n# Get the X/Y\ncityHallXY = get_xy_from_geometry(cityHall.to_crs(epsg=3857))\n\n# Run the k nearest algorithm\nnbrs = NearestNeighbors(n_neighbors=1)\nnbrs.fit(cityHallXY)\ncityHallDist, _ = nbrs.kneighbors(salesXY)\n\n# Add the new feature\nsales[\"logDistCityHall\"] = np.log10(cityHallDist.mean(axis=1))\n\n\n\n\nFEATURE 6: DISTANCE TO 5 NEAREST RESIDENTIAL CONSTRUCTION PERMITS FROM 2022\n\n\nCode\nimport warnings\n\n# Table name\ntable_name = \"permits\"\n\n# Where clause\nwhere = \"permitissuedate &gt;= '2022-01-01' AND permitissuedate &lt; '2023-01-01'\"\nwhere = where + \" AND permitdescription='RESIDENTIAL BUILDING PERMIT'\"\n\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\n    # Query\n    permits = get_carto_data(table_name, where=where)\n\n    # Remove missing\n    not_missing = ~permits.geometry.is_empty & permits.geometry.notna()\n    permits = permits.loc[not_missing]\n\n    # Get the X/Y\n    permitsXY = get_xy_from_geometry(permits.to_crs(epsg=3857))\n\n    # Run the k nearest algorithm\n    nbrs = NearestNeighbors(n_neighbors=5)\n    nbrs.fit(permitsXY)\n    permitsDist, _ = nbrs.kneighbors(salesXY)\n\n    # Add the new feature\n    sales[\"logDistPermits\"] = np.log10(permitsDist.mean(axis=1))\n\n\n\n\nFEATURE 7: DISTANCE TO THE 5 NEAREST AGGRAVATED ASSAULT IN 2022\n\n\nCode\n# Table name\ntable_name = \"incidents_part1_part2\"\n\n# Where selection\nwhere = \"dispatch_date &gt;= '2022-01-01' AND dispatch_date &lt; '2023-01-01'\"\nwhere = where + \" AND Text_General_Code IN ('Aggravated Assault No Firearm', 'Aggravated Assault Firearm')\"\n\n# Query\nassaults = get_carto_data(table_name, where=where)\n\n# Remove missing \nnot_missing = ~assaults.geometry.is_empty & assaults.geometry.notna()\nassaults = assaults.loc[not_missing]\n    \n# Get the X/Y\nassaultsXY = get_xy_from_geometry(assaults.to_crs(epsg=3857))\n\n# Run the k nearest algorithm\nnbrs = NearestNeighbors(n_neighbors=5)\nnbrs.fit(assaultsXY)\nassaultDists, _ = nbrs.kneighbors(salesXY)\n\n# Add the new feature\nsales['logDistAssaults'] = np.log10(assaultDists.mean(axis=1))\n\n\n\n\nFEATURE 8: DISTANCE TO THE 5 NEAREST ABANDONED VEHICLE 311 CALLS IN 2022\n\n\nCode\n# Table name\ntable_name = \"public_cases_fc\"\n\n# Where selection\nwhere = \"requested_datetime &gt;= '2022-01-01' AND requested_datetime &lt; '2023-01-01'\"\nwhere = \"service_name = 'Abandoned Vehicle'\"\n\n# Query\ncars = get_carto_data(table_name, where=where)\n\n# Remove missing\nnot_missing = ~cars.geometry.is_empty & cars.geometry.notna()\ncars = cars.loc[not_missing]\n\n# Get the X/Y\ncarsXY = get_xy_from_geometry(cars.to_crs(epsg=3857))\n\n# Run the k nearest algorithm\nnbrs = NearestNeighbors(n_neighbors=5)\nnbrs.fit(carsXY)\ncarDists, _ = nbrs.kneighbors(salesXY)\n\n# Handle any sales that have 0 distances\ncarDists[carDists == 0] = 1e-5  # a small, arbitrary value\n\n# Add the new feature\nsales[\"logDistCars\"] = np.log10(carDists.mean(axis=1))\n\n\n\n\nFEATURE 9: DISTANCE TO THE 5 NEAREST HOMELESS ENCAMPMENT REQUEST IN 2022\n\n\nCode\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.neighbors import NearestNeighbors\n\n# Assuming salesXY is your input data\n# Step 1: Impute NaN values\nimputer = SimpleImputer(strategy='mean')\nsalesXY_imputed = imputer.fit_transform(salesXY)\n\n# Step 2: Continue with the rest of your code\ntable_name = \"public_cases_fc\"\nwhere = \"requested_datetime &gt;= '2022-01-01' AND requested_datetime &lt; '2023-01-01'\"\nwhere = \"service_name = 'Homeless Encampment Request'\"\n\nencampment = get_carto_data(table_name, where=where)\n\nnot_missing = ~encampment.geometry.is_empty & encampment.geometry.notna()\nencampment = encampment.loc[not_missing]\n\nencampmentXY = get_xy_from_geometry(encampment.to_crs(epsg=3857))\n\nnbrs = NearestNeighbors(n_neighbors=5)\nnbrs.fit(encampmentXY)\n\nencampmentDists, _ = nbrs.kneighbors(salesXY_imputed)\n\nencampmentDists[encampmentDists == 0] = 1e-5\n\nsales[\"logDistencampment\"] = np.log10(encampmentDists.mean(axis=1))\n\n\n\n\nCorrelations Matrix of all of our features\n\n\n\n\n\n\n\nPrediction model result after adding features\n\nSet Up Transformer for Numerical and categorical columns:\n\n\nCode\n# Numerical columns\nnum_cols = [\n    \"total_livable_area\",\n    \"total_area\",\n    \"garage_spaces\",\n    \"frontage\",\n    \"fireplaces\",\n    \"number_of_bathrooms\",\n    \"number_of_bedrooms\",\n    \"number_stories\",\n    \"logDistGraffiti\",\n    \"logDistSubway\",\n    \"logDistUniv\",\n    \"logDistParks\",\n    \"logDistCityHall\", \n    \"logDistPermits\",\n    \"logDistAssaults\",\n    \"logDistCars\",\n    \"logDistencampment\"\n]\n\n# Categorical columns\ncat_cols = [\"exterior_condition\",\"interior_condition\",\"zip_code\",\"garage_type\",\"zoning\"]\n\n# Set up the column transformer with two transformers\ntransformer = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    ]\n)\n\n# Two steps in pipeline: preprocessor and then regressor\npipe = make_pipeline(\n    transformer, RandomForestRegressor(n_estimators=20, random_state=42)\n)\n\n# Split the data 70/30\ntrain_set, test_set = train_test_split(sales, test_size=0.3, random_state=42)\n\n# the target labels\ny_train = np.log(train_set[\"sale_price\"])\ny_test = np.log(test_set[\"sale_price\"])\n\n# Fit the training set\npipe.fit(train_set, y_train);\n\n# What's the test score?\npipe.score(test_set, y_test)\n\n\n0.7897739366605911\n\n\n\n\n\nAdding spatial features to the house price model resulted in a score improvement from 0.74 to 0.78"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Data form Philadelphia’s Open Data portal are used in building this model. The dataset that is expected to have an impact has been selected to create this model.\n\n\n\n\n\nPhiladelphia Properties and Current Assessments\nSource: Philadelphia Properties and Current Assessments.\n\n\n311 Service and Information Requests\nSource: 311 Service and Information Requests.\n\n\nPublic Amenities\nSource: Opendataphilly. OSM Wikipedia"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HOUSING MARKET PREDICTION",
    "section": "",
    "text": "Predicting house prices is important for real estate company and for potential homebuyers or sellers. For the real estate, house prices prediction can be crucial for inform market analysis, strategies, risk mitigation, and particularly for price competition. Good house price predcition considered to be advantage for the real estate company in competition with the others. Potential homebuyers and sellers are also benefit from the existence of an accurate house price prediction model.it empower potential buyers and sellers to make a data-driven decision, allocate budget effectively, negotiate confidently, and assess potential investment in a property.\nObtaining accurate house price prediction is challenging. There is no such thing as a perfect prediction, but we can make a better prediction for a house price. There are many factors related to house pricing such as internal characteristic from property assessment, public amenities and disamenities nearby, crimes nearby, and market price condition. In this project, we deliver the house price prediction for city of Philadelphia using data from Philadelphia’s Open Data portal. This is the most challenging part in this project, to find correlating factors or variables that directly affect the house price in one area.\nThis website will provide the best overview of the house price prediction process, including the variables used for price-changing factors, the model-building process, and the methods for validating the accuracy of the model\n\n\n\n\n\n\nImportant\n\n\n\nThis prediction model is created to provide house price prediction in city of Philadelphia based on factos such as internal characteristic and public amenities and/or disamenities."
  },
  {
    "objectID": "index.html#fundamentals",
    "href": "index.html#fundamentals",
    "title": "HOUSING MARKET PREDICTION",
    "section": "",
    "text": "Predicting house prices is important for real estate company and for potential homebuyers or sellers. For the real estate, house prices prediction can be crucial for inform market analysis, strategies, risk mitigation, and particularly for price competition. Good house price predcition considered to be advantage for the real estate company in competition with the others. Potential homebuyers and sellers are also benefit from the existence of an accurate house price prediction model.it empower potential buyers and sellers to make a data-driven decision, allocate budget effectively, negotiate confidently, and assess potential investment in a property.\nObtaining accurate house price prediction is challenging. There is no such thing as a perfect prediction, but we can make a better prediction for a house price. There are many factors related to house pricing such as internal characteristic from property assessment, public amenities and disamenities nearby, crimes nearby, and market price condition. In this project, we deliver the house price prediction for city of Philadelphia using data from Philadelphia’s Open Data portal. This is the most challenging part in this project, to find correlating factors or variables that directly affect the house price in one area.\nThis website will provide the best overview of the house price prediction process, including the variables used for price-changing factors, the model-building process, and the methods for validating the accuracy of the model\n\n\n\n\n\n\nImportant\n\n\n\nThis prediction model is created to provide house price prediction in city of Philadelphia based on factos such as internal characteristic and public amenities and/or disamenities."
  }
]